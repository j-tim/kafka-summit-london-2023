# Docker compose file format 3.9 Required Docker Engine 19.03.0+
# For more information see: https://docs.docker.com/compose/compose-file/compose-versioning/
version: '3.9'

services:

  # Confluent Kafka Docker image see: https://hub.docker.com/r/confluentinc/cp-kafka/
  # Confluent Platform and Apache Kafka Compatibility:
  # https://docs.confluent.io/current/installation/versions-interoperability.html
  kafka:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION}
    container_name: kafka
    hostname: kafka
    environment:
      # KAFKA_ADVERTISED_LISTENERS: comma-separated list of listeners with their the host/ip and port.
      # This is the metadata that’s passed back to clients.
      # LISTENER_DOCKER_INTERNAL: This will make Kafka accessible from outside of the Docker network (your machine) port: 9092.
      # LISTENER_DOCKER_EXTERNAL: This will make Kafka accessible to other Docker containers by advertising it’s
      # location on the Docker network port: 29092
      KAFKA_LISTENERS: LISTENER_DOCKER_INTERNAL://:29092,LISTENER_DOCKER_EXTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:29092,LISTENER_DOCKER_EXTERNAL://localhost:9092
      # Key/value pairs for the security protocol to use, per listener name
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      # The same ZooKeeper port is specified here as the previous container.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      # The KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR is set to 1 for a single-node cluster. Unless you have three or more
      # nodes you do not need to change this from the default.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      # Whether to auto create topics when data is published for the first time to a topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      JMX_PORT: 9999
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.host=0.0.0.0 -Djava.rmi.server.hostname=0.0.0.0 -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.rmi.port=9999
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
      EXTRA_ARGS: -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.18.0.jar=1234:/usr/share/jmx-exporter/kafka_broker.yml
    ports:
      - 9092:9092
      - 9999:9999
    volumes:
      - ./observability/jmx-exporter/:/usr/share/jmx-exporter
    healthcheck:
      test: echo srvr | nc kafka 9092 || exit 1
      interval: 5s
      retries: 10
    depends_on:
      zookeeper:
        condition: service_healthy

  # Confluent Zookeeper Docker image see: https://hub.docker.com/r/confluentinc/cp-zookeeper/
  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION}
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - 2181:2181
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      interval: 10s
      retries: 20

  # Confluent Schema Registry Docker image see: https://hub.docker.com/r/confluentinc/cp-schema-registry
  # Schema Registry: http://localhost:8081
  schema-registry:
    image: confluentinc/cp-schema-registry:${CONFLUENT_PLATFORM_VERSION}
    hostname: schema-registry
    container_name: schema-registry
    environment:
      # Connects to the docker internal network port: 29092
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    ports:
      - 8081:8081
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      interval: 5s
      retries: 10
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8081

  # https://www.jaegertracing.io/docs/next-release/getting-started/#all-in-one
  jaeger:
    image: jaegertracing/all-in-one:1.48
    container_name: jaeger
    restart: on-failure
    ports:
      - "16686:16686"    # serve frontend
      - "14268"          # HTTP collector thrift
      - "14250"          # HTTP collector proto

  loki:
    image: grafana/loki:2.8.4
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    depends_on:
      - collector

  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    environment:
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    ports:
      - "3000:3000"
    volumes:
      - ./observability/grafana/provisioning/datasources/grafana-datasource.yml:/etc/grafana/provisioning/datasources/grafana-datasource.yml
      - ./observability/grafana/provisioning/dashboards/grafana-dashboard.yml:/etc/grafana/provisioning/dashboards/grafana-dashboard.yml
      - ./observability/grafana/dashboards:/etc/grafana/dashboards
    depends_on:
      - loki

  collector:
    image: otel/opentelemetry-collector-contrib:0.84.0
    container_name: collector
    volumes:
      - ./observability/opentelemetry/collector/otel-config.yaml:/otel-config.yaml
    command: [ "--config=/otel-config.yaml" ]
    depends_on:
      kafka:
        condition: service_healthy
    expose:
      - "4317"
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP http receiver
      - "55679:55679" # zpages extension

  # Login: http://localhost
  #
  # admin: username: admin@conduktor.io password: admin
  # user: username: user@conduktor.io password: user
  conduktor:
    image: conduktor/conduktor-platform:1.17.3
    hostname: conduktor
    container_name: conduktor
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost/platform/api/modules/health/live"
        ]
      interval: 30s
      start_period: 120s # Leave time for the psql init scripts to run
      timeout: 5s
      retries: 3
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - 80:80
    environment:
      ORGANISATION_NAME: "default"
      CDK_LISTENING_PORT: 80
      CDK_ADMIN_EMAIL: admin@conduktor.io
      CDK_ADMIN_PASSWORD: admin
      CDK_CLUSTERS_0_ID: "default"
      CDK_CLUSTERS_0_NAME: "Local Kafka Cluster"
      CDK_CLUSTERS_0_COLOR: "#0013E7"
      CDK_CLUSTERS_0_BOOTSTRAPSERVERS: "PLAINTEXT://kafka:29092"
      CDK_CLUSTERS_0_SCHEMAREGISTRY_URL: "http://schema-registry:8081"

  prometheus:
    image: prom/prometheus:v2.46.0
    container_name: prometheus
    restart: on-failure
    depends_on:
      - kafka-lag-exporter
    extra_hosts:
      - "host.docker.internal:host-gateway"
    # https://prometheus.io/docs/prometheus/latest/storage/#remote-storage-integrations
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --web.enable-remote-write-receiver
      - --enable-feature=exemplar-storage
    volumes:
      - ./observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  tempo:
    image: grafana/tempo:2.2.1
    container_name: tempo
    command: [ "-config.file=/etc/tempo.yml" ]
    healthcheck:
      interval: 5s
      retries: 10
      test: wget --no-verbose --tries=1 --spider http://localhost:3200/status || exit 1
    ports:
      - "3200:3200"   # tempo
      - "4318"        # otlp http
      - "4317"        # otlp grpc
      - "14268:14268" # jaeger ingest
    volumes:
      - ./observability/tempo/tempo.yml:/etc/tempo.yml

  kafka-lag-exporter:
    image: seglo/kafka-lag-exporter:0.8.2
    container_name: kafka-lag-exporter
    volumes:
      - ./observability/kafka-lag-exporter/application.conf:/opt/docker/conf/application.conf
      - ./observability/kafka-lag-exporter/logback.xml:/opt/docker/conf/logback.xml
    command: "/opt/docker/bin/kafka-lag-exporter -Dconfig.file=/opt/docker/conf/application.conf -Dlogback.configurationFile=/opt/docker/conf/logback.xml"
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "11080:11080"      # Kafka-lag-exporter metrics endpoint
    platform: linux/amd64  # since currently the Docker image is available only on linux/amd64 OS/architecture