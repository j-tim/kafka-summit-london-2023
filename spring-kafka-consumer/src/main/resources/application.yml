server:
  port: 8082

spring:
  application:
    name: spring-kafka-consumer

  kafka:
    bootstrap-servers: localhost:9092

    consumer:
      group-id: group
      auto-offset-reset: earliest
      # Configures the Spring Kafka ErrorHandlingDeserializer that delegates to the 'real' deserializers
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        # Tells Kafka / Schema Registry that we will be using a specific Avro type
        # otherwise Kafka will expect GenericRecord to be used on the topic.
        specific.avro.reader: true

    properties:
      schema.registry.url: http://localhost:8081

kafka:
  consumer:
    call-downstream-service: true

shaky:
  service:
    api:
      url: "http://localhost:7999/api/greet"

management:
  tracing:
    sampling:
      probability: 1.0
    enabled: false

  metrics:
    tags:
      application: ${spring.application.name}
      env: local

  otlp:
    metrics:
      export:
        url: "http://localhost:4318/v1/metrics"
        resource-attributes:
          service-name: ${spring.application.name}
          service.name: ${spring.application.name}
        enabled: false
    # Be aware this configuration is custom see: OpenTelemetryTracingProperties
    # The properties are not mapped into configuration properties managed / autoconfigured by Spring Boot!
    tracing:
      endpoint: "http://localhost:4317"

  # Open up all Spring Boot Actuator endpoints
  endpoints:
    web:
      exposure:
        include: "*"

  endpoint:
    health:
      show-details: always

logging:
  pattern:
    # https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/docs/logger-mdc-instrumentation.md
    level: '%5p [${spring.application.name:},%mdc{trace_id:-},%mdc{span_id:-}]'
  level:
    root: info
    org.apache.kafka.clients.consumer: info

